import $cp.lib.`out.jar`
import com.aktit.query.DI._
import consoleService._

// import this for avro support
import $ivy.`org.apache.spark::spark-avro:3.0.0`

val RootDir = "data"
val ScanRootDir = "data-to-scan"

val tables = Seq(
  mountTable("budget", s"$RootDir/budget.csv", format = "csv", csvHeaders = true), // mount a csv file which should have headers
  mountTable("tweets", s"$RootDir/tweets"), // parquet by default, tweets should be a directory generated by spark
  mountTable("tweets_avro", s"$RootDir/tweets_avro", format = "avro"), // same like before but avro format
  mountTable("users", s"$RootDir/users"),
  mountTable("users_avro", s"$RootDir/users_avro", format = "avro")
) ++ scan(s"data-to-scan", "scanned_", csvHeaders = true) // scan data-to-scan directory, any table found will be mounted with scanned_${file or dir name} name
terminal(tables)
