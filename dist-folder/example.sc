

// import this for avro support
import $ivy.`org.apache.spark::spark-avro:3.0.0`

val RootDir = "data"
val ScanRootDir = "data-to-scan"
com.aktit.query.service.ConsoleService.initConsole()

val tables = Seq(
  table("budget", s"$RootDir/budget.csv", format = "csv", csvHeaders = true), // mount a csv file which should have headers
  table("tweets", s"$RootDir/tweets"), // parquet by default, tweets should be a directory generated by spark
  table("tweets_avro", s"$RootDir/tweets_avro", format = "avro"), // same like before but avro format
  table("users", s"$RootDir/users"),
  table("users_avro", s"$RootDir/users_avro", format = "avro")
)
val scannedTables = scan(s"data-to-scan", "scanned_", csvHeaders = true) // scan data-to-scan directory, any table found will be mounted with scanned_${file or dir name} name

val mounted = mountAll(tables ++ scannedTables)
terminal(mounted)
